{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# This notebook focuses on preprocessing the HelpSteer dataset for training:\n",
        "\n",
        "### Dataset Loading and Analysis:\n",
        "\n",
        "Loads data from \"cleaned_helpsteer_subset.json\"\n",
        "\n",
        "1.   Loads data from \"cleaned_helpsteer_subset.json\"\n",
        "2.   Analyzes preference distributions to understand how often response 1 or 2 is preferred\n",
        "3. Extracts reasoning scores from individual annotations\n",
        "\n",
        "\n",
        "### Tokenization and Formatting:\n",
        "\n",
        "\n",
        "1.   Uses DistilBERT tokenizer to prepare the text data\n",
        "2.   Structures context with proper separators\n",
        "3. Tokenizes contexts with 512 max tokens and responses with 384 max tokens\n",
        "4. Converts preference values to binary labels (0 for preference toward response 1, 1 for response 2)\n",
        "\n",
        "\n",
        "### Train/Validation Split:\n",
        "\n",
        "Creates a stratified 80/20 split to ensure balanced distribution of preferences\n",
        "\n",
        "Saves the tokenized data and indices to disk for later use"
      ],
      "metadata": {
        "id": "pTn4fRQl9m_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the pretrained tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\", use_fast=True)\n",
        "\n",
        "# Load the dataset\n",
        "print(\"Loading dataset...\")\n",
        "df = pd.read_json(\"cleaned_helpsteer_subset.json\", lines=True)\n",
        "\n",
        "# Analyze label distribution\n",
        "print(\"Analyzing label distribution...\")\n",
        "preference_counts = df['overall_preference'].value_counts()\n",
        "print(f\"Label distribution:\\n{preference_counts}\")\n",
        "print(\"Preference distribution (negative = response 1, positive = response 2):\")\n",
        "for val in sorted(preference_counts.index):\n",
        "    print(f\"  {val}: {preference_counts[val]} examples ({preference_counts[val]/len(df)*100:.2f}%)\")\n",
        "\n",
        "# Calculate overall preference direction\n",
        "neg_count = sum(preference_counts.get(val, 0) for val in [-3, -2, -1])\n",
        "pos_count = sum(preference_counts.get(val, 0) for val in [1, 2, 3])\n",
        "neutral_count = preference_counts.get(0, 0)\n",
        "print(f\"\\nOverall: {neg_count} response_1 preferred ({neg_count/len(df)*100:.2f}%)\")\n",
        "print(f\"Overall: {pos_count} response_2 preferred ({pos_count/len(df)*100:.2f}%)\")\n",
        "print(f\"Overall: {neutral_count} neutral ({neutral_count/len(df)*100:.2f}%)\")\n",
        "\n",
        "# Extract and analyze reasoning scores\n",
        "print(\"Analyzing reasoning scores...\")\n",
        "def get_reasoning_score(row):\n",
        "    scores = [int(item['score']) for item in row['individual_preference'] if 'score' in item]\n",
        "    return np.mean(scores) if scores else 0\n",
        "\n",
        "df['reasoning_score'] = df.apply(get_reasoning_score, axis=1)\n",
        "print(f\"Mean reasoning score: {df['reasoning_score'].mean()}\")\n",
        "print(f\"Min reasoning score: {df['reasoning_score'].min()}\")\n",
        "print(f\"Max reasoning score: {df['reasoning_score'].max()}\")\n",
        "\n",
        "# Function to tokenize text with improved formatting\n",
        "def tokenize_text(text, max_length=384):\n",
        "    return tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "# Function to combine context in a more structured way\n",
        "def format_context(context_list):\n",
        "    # Use tokenizer's special tokens to separate context parts\n",
        "    return tokenizer.sep_token.join(context_list)\n",
        "\n",
        "# Prepare improved tokenized data\n",
        "print(\"Tokenizing data with improved formatting...\")\n",
        "tokenized_data = {\n",
        "    \"response1\": [],\n",
        "    \"response2\": [],\n",
        "    \"contexts\": [],\n",
        "    \"overall_preference\": [],\n",
        "    \"reasoning_scores\": [],  # Add reasoning scores\n",
        "    \"reasoning_text\": []\n",
        "}\n",
        "\n",
        "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    # Format context with proper separators\n",
        "    context = format_context(row[\"context_list\"])\n",
        "\n",
        "    # Tokenize with appropriate lengths\n",
        "    # Allocate more tokens to context, less to responses\n",
        "    tokenized_data[\"contexts\"].append(tokenize_text(context, max_length=512))\n",
        "    tokenized_data[\"response1\"].append(tokenize_text(row[\"response1\"], max_length=384))\n",
        "    tokenized_data[\"response2\"].append(tokenize_text(row[\"response2\"], max_length=384))\n",
        "\n",
        "    # Convert preference to binary based on numeric values\n",
        "    # Negative values indicate response_1 is preferred, positive values indicate response_2 is preferred\n",
        "    preference_value = row[\"overall_preference\"]\n",
        "    binary_preference = 0 if preference_value < 0 else 1 if preference_value > 0 else (0.5 if preference_value == 0 else 0)\n",
        "    tokenized_data[\"overall_preference\"].append(binary_preference)\n",
        "\n",
        "    # Store reasoning information\n",
        "    reasoning_text = \" \".join([r[\"reasoning\"] for r in row[\"individual_preference\"] if \"reasoning\" in r])\n",
        "    tokenized_data[\"reasoning_text\"].append(reasoning_text)\n",
        "    tokenized_data[\"reasoning_scores\"].append(row.get('reasoning_score', 0))\n",
        "\n",
        "# Create train/val splits with stratification\n",
        "print(\"Creating train/validation splits...\")\n",
        "indices = list(range(len(tokenized_data[\"contexts\"])))\n",
        "labels = tokenized_data[\"overall_preference\"]\n",
        "\n",
        "train_indices, val_indices = train_test_split(\n",
        "    indices,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=labels  # Ensure balanced distribution\n",
        ")\n",
        "\n",
        "# Save train/val indices for later use\n",
        "indices_data = {\n",
        "    \"train_indices\": train_indices,\n",
        "    \"val_indices\": val_indices\n",
        "}\n",
        "\n",
        "# Save the tokenized data\n",
        "print(\"Saving tokenized data...\")\n",
        "torch.save(tokenized_data, \"tokenized_helpsteer_improved.pt\")\n",
        "torch.save(indices_data, \"helpsteer_indices.pt\")\n",
        "\n",
        "print(\"Data preparation complete!\")\n",
        "\n",
        "# Print some statistics about the processed data\n",
        "print(f\"Total examples: {len(tokenized_data['contexts'])}\")\n",
        "print(f\"Training examples: {len(train_indices)}\")\n",
        "print(f\"Validation examples: {len(val_indices)}\")\n",
        "\n",
        "# Check a sample to verify tokenization\n",
        "sample_idx = 0\n",
        "sample_context = tokenizer.decode(tokenized_data[\"contexts\"][sample_idx][\"input_ids\"][0], skip_special_tokens=False)\n",
        "print(\"\\nSample tokenized context (with special tokens):\")\n",
        "print(sample_context[:500] + \"...\" if len(sample_context) > 500 else sample_context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUQlj8UkOSVI",
        "outputId": "90b6a45d-d54c-494b-902e-2503368a912e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Analyzing label distribution...\n",
            "Label distribution:\n",
            "overall_preference\n",
            "-2    4560\n",
            " 2    4537\n",
            " 1    3084\n",
            "-1    2848\n",
            " 3    2323\n",
            "-3    2271\n",
            " 0     377\n",
            "Name: count, dtype: int64\n",
            "Preference distribution (negative = response 1, positive = response 2):\n",
            "  -3: 2271 examples (11.36%)\n",
            "  -2: 4560 examples (22.80%)\n",
            "  -1: 2848 examples (14.24%)\n",
            "  0: 377 examples (1.88%)\n",
            "  1: 3084 examples (15.42%)\n",
            "  2: 4537 examples (22.68%)\n",
            "  3: 2323 examples (11.62%)\n",
            "\n",
            "Overall: 9679 response_1 preferred (48.39%)\n",
            "Overall: 9944 response_2 preferred (49.72%)\n",
            "Overall: 377 neutral (1.88%)\n",
            "Analyzing reasoning scores...\n",
            "Mean reasoning score: 0.02179166666666666\n",
            "Min reasoning score: -3.0\n",
            "Max reasoning score: 3.0\n",
            "Tokenizing data with improved formatting...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20000/20000 [01:36<00:00, 206.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating train/validation splits...\n",
            "Saving tokenized data...\n",
            "Data preparation complete!\n",
            "Total examples: 20000\n",
            "Training examples: 16000\n",
            "Validation examples: 4000\n",
            "\n",
            "Sample tokenized context (with special tokens):\n",
            "[CLS] rephrase “ a word about robot software “ [SEP] let ' s discuss the topic of robot software. [SEP] rephrase the future of robotics and robots [SEP] the potential developments and advancements in the field of robotics and robots. [SEP] make it simple and short [SEP] the future of robotics and robots. [SEP] another one [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [P...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AcM8_oSqS22O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}